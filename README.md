# üìû PostCallTranscriptionAnalyser

Analyze customer service call transcripts with AI!  
Get actionable feedback, agent scoring, and complaint type detection ‚Äî all powered by LLMs via Ollama.

---

## üöÄ Features

- ü§ñ **Agent Scoring:** Rates empathy, problem-solving, and professionalism.
- üìù **Complaint Type Detection:** Identifies the main issue from a call.
- üó£Ô∏è **Speaker Feedback:** Generates feedback for each unique speaker.

---

## üõ†Ô∏è API Endpoints

### ‚úÖ Health Check

`GET /health`  
Returns API health status.

---

### üèÖ Score Transcript and Extract Complaint 

`POST /score`

**Request:**
```json
{
  "transcript_id": "1"
}
```
**Response:**  
Score, feedback, and complaint type in JSON.

---

### üìã Generate Call Report

`POST /GenerateReport`

**Request:**
```json
{
  "transcript_id": "1"
}
```
**Response:**  
Speaker-wise feedback in JSON.

---

## ‚ö° Quickstart

1. **Install dependencies**
   ```sh
   pip install -r requirements.txt
   ```

2. **Start Ollama** (ensure `llama3` model is available)

3. **Run the app**
   ```sh
   python app.py
   ```

   Or with Docker:
   ```sh
   docker build -t postcall-analyser .
   docker run -p 5000:5000 postcall-analyser
   ```

---

## üìÇ Project Structure

- `app.py` ‚Äî Flask API server
- `TranscriptAnalyzer.py` ‚Äî Transcript analysis logic
- `requirements.txt` ‚Äî Python dependencies
- `Dockerfile` ‚Äî Containerization

---

## üí° Example Usage

```sh
curl -X POST http://localhost:5000/score -H "Content-Type: application/json" -d '{"transcript_id": "1"}'
```

---

## üßë‚Äçüíª Requirements

- Python 3.11+
- Flask
- Ollama Python client
- Ollama server with `llama3` model

---

> Made with ‚ù§Ô∏è for call center QA prototyping.